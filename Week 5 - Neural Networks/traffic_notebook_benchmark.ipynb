{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.7.2 64-bit ('cs50ai': venv)",
   "display_name": "Python 3.7.2 64-bit ('cs50ai': venv)",
   "metadata": {
    "interpreter": {
     "hash": "368c6419a121e47d2ba7a65faf6952e0c2adb824b19c5e4d8f1ab553f226a136"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np \n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import traffic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 10\n",
    "IMG_WIDTH = 30\n",
    "IMG_HEIGHT = 30\n",
    "NUM_CATEGORIES = 43\n",
    "TEST_SIZE = 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[[ 80,  78,  75],\n",
       "        [ 78,  76,  74],\n",
       "        [ 84,  87,  86],\n",
       "        ...,\n",
       "        [ 75,  75,  68],\n",
       "        [ 68,  69,  65],\n",
       "        [ 66,  67,  66]],\n",
       "\n",
       "       [[ 86,  84,  83],\n",
       "        [ 82,  80,  80],\n",
       "        [ 84,  89,  90],\n",
       "        ...,\n",
       "        [ 78,  77,  73],\n",
       "        [ 75,  78,  76],\n",
       "        [ 78,  80,  80]],\n",
       "\n",
       "       [[ 80,  78,  78],\n",
       "        [ 86,  85,  86],\n",
       "        [ 91,  90,  93],\n",
       "        ...,\n",
       "        [ 72,  74,  72],\n",
       "        [ 69,  74,  73],\n",
       "        [ 74,  78,  78]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[139, 134, 133],\n",
       "        [132, 127, 122],\n",
       "        [124, 121, 112],\n",
       "        ...,\n",
       "        [ 89,  94,  94],\n",
       "        [ 91,  98,  97],\n",
       "        [ 99, 103,  99]],\n",
       "\n",
       "       [[ 99,  95,  91],\n",
       "        [103,  98,  91],\n",
       "        [ 89,  85,  74],\n",
       "        ...,\n",
       "        [ 95, 101, 103],\n",
       "        [104, 113, 110],\n",
       "        [ 98, 104,  96]],\n",
       "\n",
       "       [[ 87,  84,  85],\n",
       "        [107, 101,  95],\n",
       "        [ 79,  74,  61],\n",
       "        ...,\n",
       "        [ 95, 102, 102],\n",
       "        [ 90, 102,  99],\n",
       "        [ 89,  97,  90]]], dtype=uint8)"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "img = cv2.imread('./gtsrb/0/00000_00000.ppm', cv2.IMREAD_COLOR)\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv2.imshow('image', img)\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Total: 840\n840\n"
     ]
    }
   ],
   "source": [
    "images, labels = traffic.load_data('gtsrb-small')\n",
    "\n",
    "print(f'Total: {len(images)}')\n",
    "print(len(labels))"
   ]
  },
  {
   "source": [
    "## Benchmark logistic regression model\n",
    "### Small dataset"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import KFold, cross_val_score, train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(840, 2700)"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "# prepare X\n",
    "X_raw = np.array(images)\n",
    "X = X_raw.reshape((X_raw.shape[0], -1))\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(840,)"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "# prepare y\n",
    "y = np.array(labels)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rescale \n",
    "X = X/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare train-test data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.7s finished\n"
     ]
    }
   ],
   "source": [
    "# initiate cross-validation\n",
    "cv = KFold(n_splits=10, random_state=123, shuffle=True)\n",
    "# create model\n",
    "model = LogisticRegression(verbose=1)\n",
    "# evaluate model\n",
    "scores = cross_val_score(model, X_train, y_train, scoring='accuracy', cv=cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy: 0.999 with std: 0.004\n"
     ]
    }
   ],
   "source": [
    "# report performance\n",
    "print(f'Accuracy: {np.mean(scores):.3f} with std: {np.std(scores):.3f}')"
   ]
  },
  {
   "source": [
    "### Large dataset"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Total: 26640\n26640\n"
     ]
    }
   ],
   "source": [
    "images, labels = traffic.load_data('gtsrb')\n",
    "\n",
    "print(f'Total: {len(images)}')\n",
    "print(len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(21312, 2700)\n(5328, 2700)\n(21312,)\n(5328,)\n"
     ]
    }
   ],
   "source": [
    "# prepare X\n",
    "X_raw = np.array(images)\n",
    "X = X_raw.reshape((X_raw.shape[0], -1))\n",
    "# rescale X\n",
    "X = X/255\n",
    "# prepare y\n",
    "y = np.array(labels)\n",
    "y.shape\n",
    "\n",
    "# prepare train-test data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   49.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   52.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   54.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   50.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   50.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   56.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   50.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   51.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   53.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   54.0s finished\n"
     ]
    }
   ],
   "source": [
    "# initiate cross-validation\n",
    "cv = KFold(n_splits=10, random_state=123, shuffle=True)\n",
    "# create model\n",
    "model = LogisticRegression(verbose=1)\n",
    "# evaluate model\n",
    "scores = cross_val_score(model, X_train, y_train, scoring='accuracy', cv=cv, error_score='raise')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy: 0.926 with std: 0.005\n"
     ]
    }
   ],
   "source": [
    "# report performance\n",
    "print(f'Accuracy: {np.mean(scores):.3f} with std: {np.std(scores):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([0.9282364 , 0.934803  , 0.92679493, 0.9221023 , 0.92820272,\n",
       "       0.92867198, 0.91834819, 0.93007977, 0.92397935, 0.91787893])"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "scores"
   ]
  }
 ]
}